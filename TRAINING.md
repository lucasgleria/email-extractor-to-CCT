# Guia Completo: Treinamento e Melhoria do Modelo de Extra√ß√£o

Este guia explica **como funciona** o sistema de extra√ß√£o, **como treinar** um modelo customizado e **estrat√©gias avan√ßadas** para torn√°-lo cada vez mais inteligente e preciso.

## üìö √çndice

1. [Como Funciona o Sistema Atual](#como-funciona-o-sistema-atual)
2. [Coletando Dados de Qualidade](#coletando-dados-de-qualidade)
3. [Treinando Seu Primeiro Modelo](#treinando-seu-primeiro-modelo)
4. [Entendendo o Pipeline de Extra√ß√£o](#entendendo-o-pipeline-de-extra√ß√£o)
5. [Estrat√©gias para Melhorar o Modelo](#estrat√©gias-para-melhorar-o-modelo)
6. [Troubleshooting e Dicas Avan√ßadas](#troubleshooting-e-dicas-avan√ßadas)

---

## Como Funciona o Sistema Atual

O sistema usa uma **abordagem h√≠brida** que combina tr√™s estrat√©gias:

### 1. **Heur√≠sticas Baseadas em Regras** (Sempre Ativas)
- **Label-based**: Procura por palavras-chave (aliases) como "MAWB", "REFERENCIA", "CONSIGNEE"
- **Pattern-based**: Usa express√µes regulares para identificar padr√µes (ex: 11 d√≠gitos = MAWB, 3 letras = IATA)
- **Proximity boost**: Quando encontra um label, busca valores pr√≥ximos nas linhas seguintes

**Pontua√ß√£o**: Cada m√©todo tem um peso:
- Label match: **0.4** (mais confi√°vel)
- Pattern match: **0.3** (m√©dio)
- Proximity: **0.2** (menor, mas √∫til)

### 2. **Modelo de Machine Learning** (Opcional, mas Recomendado)
- Usa **TF-IDF** (Term Frequency-Inverse Document Frequency) para extrair caracter√≠sticas do texto
- **Regress√£o Log√≠stica** para classificar se uma linha cont√©m o valor correto
- Treinado com **seus dados corrigidos** para aprender padr√µes espec√≠ficos dos seus e-mails

### 3. **Sistema de Pontua√ß√£o Combinado**
O sistema **combina** as pontua√ß√µes de heur√≠sticas + modelo e escolhe o candidato com maior score.

```
Score Final = Score Heur√≠sticas + Score Modelo
Melhor Candidato = Maior Score Final (ap√≥s valida√ß√£o)
```

---

## Coletando Dados de Qualidade

### Por que Dados de Qualidade S√£o Cr√≠ticos?

O modelo aprende **exatamente** com os dados que voc√™ fornece. Se voc√™ corrigir erros consistentemente, o modelo aprender√° esses padr√µes.

### Estrat√©gia de Coleta

#### Fase 1: Coleta Inicial (50-100 exemplos)
1. **Processe e-mails variados**: diferentes remetentes, layouts, formatos
2. **Corrija TODOS os erros**: mesmo pequenos, para ensinar o modelo
3. **Mantenha consist√™ncia**: se "REF" e "REFERENCIA" s√£o a mesma coisa, sempre use o mesmo formato

#### Fase 2: Casos Especiais (50-100 exemplos adicionais)
1. **E-mails dif√≠ceis**: dark mode, baixa qualidade, layouts n√£o padronizados
2. **Casos limite**: m√∫ltiplos MAWBs, valores ausentes, formatos incomuns
3. **Erros comuns**: identifique padr√µes de erro e adicione mais exemplos desses casos

#### Fase 3: Refinamento Cont√≠nuo (iterativo)
- Ap√≥s cada treinamento, teste o modelo
- Identifique novos erros
- Adicione exemplos desses erros e retreine

### Dicas de Ouro para Dados de Qualidade

‚úÖ **FA√áA:**
- Corrija valores mesmo quando parecem corretos mas est√£o em formato diferente
- Inclua exemplos onde campos est√£o **ausentes** (deixe vazio, n√£o invente)
- Mantenha formato consistente (ex: sempre "GRU" n√£o "S√£o Paulo (GRU)")

‚ùå **N√ÉO FA√áA:**
- Deixar valores incorretos "porque est√° quase certo"
- Misturar formatos (√†s vezes "REF123", outras "123-REF")
- Incluir dados de teste ou fict√≠cios

---

## Treinando Seu Primeiro Modelo

### Pr√©-requisitos

- Pelo menos **50-100 exemplos** corrigidos e salvos
- Acesso ao Google Colab (gratuito)
- Arquivo `training_data.json` exportado

### Passo a Passo Detalhado

#### Passo 1: Exportar Dados de Treinamento

1. Abra `index.html` no navegador
2. Clique em **"Export Training Data"**
3. Salve o arquivo `training_data.json` em local seguro

**Verifica√ß√£o**: Abra o JSON e confirme que cont√©m:
- `raw_text`: texto completo do OCR
- `fields`: objeto com os campos corrigidos
- `timestamp`: data de cria√ß√£o

#### Passo 2: Configurar Google Colab

1. Acesse [Google Colab](https://colab.research.google.com/)
2. Clique em **"New notebook"**
3. Renomeie o notebook (ex: "Email Extractor Training")

#### Passo 3: Upload dos Dados

1. No painel esquerdo, clique no √≠cone **"Files"** üìÅ
2. Clique no √≠cone de **upload** (‚¨ÜÔ∏è)
3. Selecione `training_data.json`
4. Aguarde o upload completar

#### Passo 4: Script de Treinamento B√°sico

Cole o script abaixo em uma c√©lula e execute (`Shift+Enter`):

## Step 1: Export Your Training Data

1.  Open the `index.html` file in your browser.
2.  Process at least 50-100 images, ensuring you correct any mistakes made by the initial rule-based extractor. The more high-quality data you provide, the better your model will be.
3.  Click the **Export Training Data** button.
4.  Save the downloaded `training_data.json` file to your computer.

## Step 2: Set Up Your Free Training Environment (Google Colab)

1.  Go to [Google Colab](https://colab.research.google.com/).
2.  Click **New notebook**.
3.  You now have a ready-to-use Python environment in the cloud.

## Step 3: Upload Your Data to Colab

1.  In the left-hand panel of your Colab notebook, click the **Files** icon.
2.  Click the **Upload to session storage** icon and select the `training_data.json` file you downloaded in Step 1.

```python
import json
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import re

# --- 1. Load the Data ---
with open('training_data.json', 'r') as f:
    data = json.load(f)

print(f"‚úÖ Carregados {len(data)} exemplos de treinamento.")

# --- 2. Preprocess and Featurize ---
def featurize(raw_text):
    """Divide o texto em linhas para an√°lise"""
    return raw_text.split('\n')

# Campos que ser√£o treinados
fields_to_train = ['REFERENCIA', 'MAWB', 'HAWB', 'DESTINO', 'DESTINO_FINAL', 'CONSIGNEE']
models = {}

for field in fields_to_train:
    print(f"\n{'='*50}")
    print(f"üìä Treinando modelo para: {field}")
    print(f"{'='*50}")

    # Criar dados de treinamento
    X_train = []
    y_train = []

    for item in data:
        lines = featurize(item['raw_text'])
        correct_value = item['fields'].get(field, '').strip()

        # Pular se n√£o houver valor correto
        if not correct_value:
            continue

        # Para cada linha, criar um exemplo
        for line in lines:
            X_train.append(line)
            # Se o valor correto est√° nesta linha, √© positivo (1), sen√£o negativo (0)
            if correct_value.upper() in line.upper():
                y_train.append(1)
            else:
                y_train.append(0)

    # Verificar se h√° exemplos positivos
    positive_count = sum(y_train)
    total_count = len(y_train)
    
    if positive_count == 0:
        print(f"‚ö†Ô∏è  Pulando {field}: nenhum exemplo positivo encontrado.")
        continue

    print(f"üìà Exemplos: {total_count} total, {positive_count} positivos ({100*positive_count/total_count:.1f}%)")

    # Dividir em treino e teste (opcional, para avalia√ß√£o)
    if len(X_train) > 20:
        X_tr, X_te, y_tr, y_te = train_test_split(X_train, y_train, test_size=0.2, random_state=42)
    else:
        X_tr, y_tr = X_train, y_train
        X_te, y_te = [], []

    # --- 3. Train the Model ---
    # TF-IDF: converte texto em vetores num√©ricos
    # Logistic Regression: classifica se a linha cont√©m o valor
    model = make_pipeline(
        TfidfVectorizer(
            ngram_range=(1, 2),  # Palavras individuais e pares
            max_features=5000,   # Limite de features (reduz tamanho do modelo)
            min_df=2            # Ignorar palavras que aparecem menos de 2 vezes
        ),
        LogisticRegression(
            class_weight='balanced',  # Balanceia classes desiguais
            max_iter=1000
        )
    )
    
    model.fit(X_tr, y_tr)
    models[field] = model
    
    # Avaliar modelo (se houver dados de teste)
    if len(X_te) > 0:
        y_pred = model.predict(X_te)
        accuracy = sum(y_pred == y_te) / len(y_te)
        print(f"‚úÖ Acur√°cia no teste: {accuracy*100:.1f}%")
    
    print(f"‚úÖ Modelo para {field} treinado com sucesso!")

# --- 4. Export the Model ---
print(f"\n{'='*50}")
print("üíæ Exportando modelo...")
print(f"{'='*50}")

exported_model = {}
for field, model in models.items():
    vectorizer = model.named_steps['tfidfvectorizer']
    classifier = model.named_steps['logisticregression']

    exported_model[field] = {
        'vocabulary': vectorizer.vocabulary_,
        'idf': list(vectorizer.idf_),
        'coef': list(classifier.coef_[0]),
        'intercept': list(classifier.intercept_)
    }

with open('model.json', 'w') as f:
    json.dump(exported_model, f)

print(f"‚úÖ Modelo exportado para model.json")
print(f"üì¶ Tamanho do arquivo: {len(json.dumps(exported_model)) / 1024:.1f} KB")
```

### Explica√ß√£o do Script

#### O que cada parte faz:

1. **TF-IDF Vectorizer**: 
   - Converte cada linha de texto em um vetor num√©rico
   - Pesos palavras importantes (que aparecem em poucos documentos) mais alto
   - `ngram_range=(1,2)`: considera palavras individuais E pares de palavras

2. **Logistic Regression**:
   - Aprende a classificar: "esta linha cont√©m o valor que procuro?"
   - `class_weight='balanced'`: ajusta para dados desbalanceados (muitas linhas negativas, poucas positivas)

3. **Exporta√ß√£o**:
   - Salva apenas o necess√°rio: vocabul√°rio, pesos (coef) e intercept
   - Tamanho pequeno para rodar no navegador

#### Passo 5: Download e Instala√ß√£o

1. No Colab, clique nos **tr√™s pontos** ao lado de `model.json`
2. Selecione **"Download"**
3. Salve na **mesma pasta** do `index.html`
4. Recarregue a p√°gina do `index.html`

O modelo ser√° carregado automaticamente! üéâ

---

## Entendendo o Pipeline de Extra√ß√£o

### Como o Sistema Usa o Modelo

Quando voc√™ processa uma imagem, o sistema:

1. **Executa OCR** ‚Üí obt√©m texto bruto
2. **Divide em linhas** ‚Üí cada linha √© um candidato
3. **Aplica heur√≠sticas** ‚Üí encontra candidatos por regras
4. **Aplica modelo** (se dispon√≠vel) ‚Üí para cada linha:
   ```javascript
   // Calcula TF-IDF da linha
   vector = tfidf(line, model.vocabulary, model.idf)
   
   // Calcula score do modelo
   score = vector * model.coef + model.intercept
   confidence = sigmoid(score)  // Converte para 0-1
   
   // Se confian√ßa > 0.5, adiciona como candidato
   if (confidence > 0.5) {
       candidatos.push({line, via: 'model', score: confidence})
   }
   ```
5. **Combina scores** ‚Üí heur√≠sticas + modelo
6. **Seleciona melhor** ‚Üí maior score ap√≥s valida√ß√£o

### Por que o Modelo Ajuda?

- **Heur√≠sticas** s√£o boas para padr√µes conhecidos (11 d√≠gitos = MAWB)
- **Modelo** aprende padr√µes espec√≠ficos dos seus e-mails:
  - Formato de refer√™ncia usado pelos seus remetentes
  - Onde CONSIGNEE geralmente aparece
  - Contexto textual que indica cada campo

---

## Estrat√©gias para Melhorar o Modelo

### 1. **Coleta Estrat√©gica de Dados**

#### Identifique Padr√µes de Erro
Ap√≥s usar o modelo, anote:
- Quais campos erram mais?
- Que tipos de e-mail causam mais erros?
- H√° formatos espec√≠ficos que confundem o sistema?

#### Foque nos Casos Dif√≠ceis
- Adicione mais exemplos dos casos que erram
- Inclua varia√ß√µes: dark mode, baixa qualidade, layouts diferentes

### 2. **Ajustes no Script de Treinamento**

#### Aumentar Features (para mais dados)
```python
TfidfVectorizer(
    ngram_range=(1, 3),  # Incluir trigramas (palavras triplas)
    max_features=10000,  # Mais features
    min_df=1            # Incluir palavras raras
)
```

#### Ajustar Threshold de Confian√ßa
No `index.html`, linha 436, voc√™ pode ajustar:
```javascript
if (confidence > 0.5) {  // Tente 0.4 para ser mais permissivo
    arr.push({i, line, via: 'model', score: confidence});
}
```

#### Treinar Modelos Separados por Remetente
Se voc√™ tem remetentes muito diferentes, treine modelos espec√≠ficos:
```python
# Agrupar por remetente (se tiver essa info nos dados)
for sender in unique_senders:
    sender_data = [d for d in data if d.get('sender') == sender]
    # Treinar modelo espec√≠fico
```

### 3. **Pr√©-processamento de Texto Melhorado**

Adicione normaliza√ß√£o antes do treinamento:
```python
def preprocess_line(line):
    # Normalizar espa√ßos
    line = ' '.join(line.split())
    # Remover caracteres especiais desnecess√°rios
    line = re.sub(r'[^\w\s\-/]', '', line)
    return line.lower().strip()

# Usar no treinamento
X_train.append(preprocess_line(line))
```

### 4. **Valida√ß√£o Cruzada e M√©tricas**

Adicione ao script para entender melhor o modelo:
```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X_train, y_train, cv=5)
print(f"Acur√°cia m√©dia (5-fold CV): {scores.mean():.3f} (+/- {scores.std()*2:.3f})")
```

### 5. **Ensemble de Modelos**

Combine m√∫ltiplos modelos:
```python
# Treinar modelo com diferentes par√¢metros
model1 = make_pipeline(TfidfVectorizer(ngram_range=(1,1)), LogisticRegression())
model2 = make_pipeline(TfidfVectorizer(ngram_range=(1,2)), LogisticRegression())

# Usar m√©dia dos scores
```

---

## Troubleshooting e Dicas Avan√ßadas

### Problema: Modelo n√£o melhora ap√≥s treinar

**Poss√≠veis causas:**
1. **Poucos dados**: < 50 exemplos por campo
2. **Dados inconsistentes**: valores corrigidos de forma diferente
3. **Overfitting**: modelo decorou exemplos, n√£o aprendeu padr√µes

**Solu√ß√µes:**
- Colete mais dados (100+ exemplos)
- Revise corre√ß√µes para consist√™ncia
- Reduza `max_features` ou aumente `min_df`

### Problema: Modelo muito grande (> 1MB)

**Solu√ß√£o:**
```python
TfidfVectorizer(
    max_features=2000,  # Reduzir vocabul√°rio
    min_df=3           # Ignorar palavras raras
)
```

### Problema: Algum campo nunca √© encontrado

**Diagn√≥stico:**
```python
# Verificar quantos exemplos positivos existem
positive_examples = sum(y_train)
print(f"Exemplos positivos: {positive_examples}")
```

**Solu√ß√£o:**
- Adicione mais exemplos desse campo
- Verifique se o valor correto realmente est√° no `raw_text`
- Ajuste threshold de confian√ßa para esse campo espec√≠fico

### Dica Avan√ßada: Feature Engineering Manual

Adicione features customizadas:
```python
def extract_features(line):
    features = []
    # N√∫mero de d√≠gitos
    features.append(len(re.findall(r'\d', line)))
    # N√∫mero de letras mai√∫sculas
    features.append(len(re.findall(r'[A-Z]', line)))
    # Cont√©m padr√£o MAWB?
    features.append(1 if re.search(r'\d{11}', line) else 0)
    return features
```

### Dica Avan√ßada: Active Learning

Ap√≥s treinar, identifique exemplos onde o modelo tem **baixa confian√ßa**:
- Esses s√£o os casos mais informativos para adicionar ao treinamento
- Priorize corrigir esses casos na pr√≥xima itera√ß√£o

---

## Checklist de Melhoria Cont√≠nua

Use este checklist para melhorar iterativamente:

- [ ] Tenho pelo menos 50 exemplos corrigidos
- [ ] Exportei e treinei o primeiro modelo
- [ ] Testei o modelo em 10-20 novos e-mails
- [ ] Identifiquei os 3 principais tipos de erro
- [ ] Adicionei mais exemplos dos casos que erram
- [ ] Retreinei o modelo
- [ ] Repeti o ciclo at√© acur√°cia satisfat√≥ria

**Meta de Acur√°cia:**
- MAWB: ‚â• 95%
- HAWB: ‚â• 90%
- DESTINO (IATA): ‚â• 90%
- Demais campos: ‚â• 80%

---

## Pr√≥ximos Passos

1. **Comece simples**: Treine com 50-100 exemplos
2. **Teste e itere**: Use o modelo, identifique erros, adicione exemplos
3. **Refine**: Ajuste par√¢metros conforme necess√°rio
4. **Automatize**: Ap√≥s 200+ exemplos, o modelo deve estar muito melhor

**Lembre-se**: Machine Learning √© um processo iterativo. Cada ciclo de coleta ‚Üí treino ‚Üí teste ‚Üí corre√ß√£o torna o modelo mais inteligente! üöÄ

---

## üìä Interpretando os Resultados do Modelo

### Entendendo as M√©tricas

Quando voc√™ treina o modelo, ele mostra algumas m√©tricas. Aqui est√° o que significam:

#### Acur√°cia (Accuracy)
- **O que √©**: Porcentagem de previs√µes corretas
- **Bom**: > 80% para campos estruturados (MAWB, HAWB)
- **Aten√ß√£o**: Pode ser enganosa se houver muitos exemplos negativos

#### Exemplos Positivos vs Negativos
- **Positivos**: Linhas que cont√™m o valor correto
- **Negativos**: Linhas que n√£o cont√™m
- **Ideal**: 5-20% de positivos (dados desbalanceados s√£o normais)

### Como o Modelo Decide

O modelo calcula um **score** para cada linha:

```python
score = (TF-IDF da linha) √ó (pesos aprendidos) + intercept
confian√ßa = sigmoid(score)  # Converte para 0-1
```

- **confian√ßa > 0.5**: Modelo acha que a linha cont√©m o valor
- **confian√ßa < 0.5**: Modelo acha que n√£o cont√©m

### Visualizando o que o Modelo Aprendeu

Adicione este c√≥digo ao script para ver as palavras mais importantes:

```python
# Ap√≥s treinar cada modelo
vectorizer = model.named_steps['tfidfvectorizer']
classifier = model.named_steps['logisticregression']

# Pegar top 10 palavras mais importantes
feature_names = vectorizer.get_feature_names_out()
coef = classifier.coef_[0]

# Ordenar por import√¢ncia (coeficiente)
top_indices = coef.argsort()[-10:][::-1]
print(f"\nüîù Top 10 palavras mais importantes para {field}:")
for idx in top_indices:
    print(f"  {feature_names[idx]}: {coef[idx]:.3f}")
```

Isso mostra quais palavras o modelo associa com cada campo!

---

## üéØ Estrat√©gias Espec√≠ficas por Campo

### REFERENCIA
- **Desafio**: Formato muito vari√°vel
- **Estrat√©gia**: Foque em exemplos com diferentes formatos (AB123, 123-ABC, etc.)
- **Dica**: O modelo aprende melhor quando h√° padr√µes consistentes no contexto

### MAWB
- **Desafio**: Pode ser confundido com outros n√∫meros (telefone, CEP)
- **Estrat√©gia**: Inclua exemplos negativos (n√∫meros de 11 d√≠gitos que N√ÉO s√£o MAWB)
- **Dica**: O modelo deve aprender o contexto (pr√≥ximo a "MAWB", "AWB")

### HAWB
- **Desafio**: Similar a REFERENCIA, mas geralmente mais curto
- **Estrat√©gia**: Diferencie claramente HAWB de REFERENCIA nos dados
- **Dica**: Se aparecerem juntos, o modelo aprender√° a diferen√ßa

### DESTINO (IATA)
- **Desafio**: Pode haver m√∫ltiplos c√≥digos IATA no texto
- **Estrat√©gia**: Inclua exemplos com m√∫ltiplos IATAs e marque qual √© o destino
- **Dica**: O modelo aprende contexto (pr√≥ximo a "destino", "to", "para")

### DESTINO_FINAL
- **Desafio**: Texto livre, sem formato fixo
- **Estrat√©gia**: Inclua muitas varia√ß√µes (cidades, DTA, recintos)
- **Dica**: O modelo precisa aprender palavras-chave contextuais

### CONSIGNEE
- **Desafio**: Nomes/raz√µes sociais variam muito
- **Estrat√©gia**: Inclua exemplos com e sem sufixos (LTDA, S/A, ME)
- **Dica**: O modelo aprende padr√µes de capitaliza√ß√£o e estrutura

---

## üîß Script Avan√ßado: Treinamento com Valida√ß√£o Detalhada

Use este script para obter insights mais profundos:

```python
import json
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

# Carregar dados
with open('training_data.json', 'r') as f:
    data = json.load(f)

def featurize(raw_text):
    return raw_text.split('\n')

fields_to_train = ['REFERENCIA', 'MAWB', 'HAWB', 'DESTINO', 'DESTINO_FINAL', 'CONSIGNEE']
models = {}

for field in fields_to_train:
    print(f"\n{'='*60}")
    print(f"üìä {field}")
    print(f"{'='*60}")
    
    X_train = []
    y_train = []
    
    for item in data:
        lines = featurize(item['raw_text'])
        correct_value = item['fields'].get(field, '').strip()
        
        if not correct_value:
            continue
        
        for line in lines:
            X_train.append(line)
            y_train.append(1 if correct_value.upper() in line.upper() else 0)
    
    if sum(y_train) == 0:
        print(f"‚ö†Ô∏è  Sem exemplos positivos")
        continue
    
    # Estat√≠sticas
    pos = sum(y_train)
    total = len(y_train)
    print(f"üìà Exemplos: {total} total | {pos} positivos ({100*pos/total:.1f}%)")
    
    # Dividir treino/teste
    if total > 20:
        X_tr, X_te, y_tr, y_te = train_test_split(
            X_train, y_train, test_size=0.2, random_state=42, stratify=y_train
        )
    else:
        X_tr, y_tr = X_train, y_train
        X_te, y_te = [], []
    
    # Treinar
    model = make_pipeline(
        TfidfVectorizer(ngram_range=(1, 2), max_features=5000, min_df=2),
        LogisticRegression(class_weight='balanced', max_iter=1000)
    )
    model.fit(X_tr, y_tr)
    models[field] = model
    
    # Avaliar
    if len(X_te) > 0:
        y_pred = model.predict(X_te)
        print(f"\nüìä Relat√≥rio de Classifica√ß√£o:")
        print(classification_report(y_te, y_pred, target_names=['Negativo', 'Positivo']))
        
        # Mostrar exemplos de erros
        print(f"\nüîç Exemplos de Falsos Positivos (modelo achou, mas n√£o √©):")
        fp_count = 0
        for i, (line, true, pred) in enumerate(zip(X_te, y_te, y_pred)):
            if true == 0 and pred == 1 and fp_count < 3:
                print(f"  - {line[:80]}...")
                fp_count += 1
        
        print(f"\nüîç Exemplos de Falsos Negativos (√©, mas modelo n√£o achou):")
        fn_count = 0
        for i, (line, true, pred) in enumerate(zip(X_te, y_te, y_pred)):
            if true == 1 and pred == 0 and fn_count < 3:
                print(f"  - {line[:80]}...")
                fn_count += 1
    
    # Top palavras
    vectorizer = model.named_steps['tfidfvectorizer']
    classifier = model.named_steps['logisticregression']
    feature_names = vectorizer.get_feature_names_out()
    coef = classifier.coef_[0]
    top_indices = coef.argsort()[-5:][::-1]
    print(f"\nüîù Top 5 palavras importantes:")
    for idx in top_indices:
        print(f"  ‚Ä¢ {feature_names[idx]}: {coef[idx]:.3f}")

# Exportar
exported_model = {}
for field, model in models.items():
    vectorizer = model.named_steps['tfidfvectorizer']
    classifier = model.named_steps['logisticregression']
    exported_model[field] = {
        'vocabulary': vectorizer.vocabulary_,
        'idf': list(vectorizer.idf_),
        'coef': list(classifier.coef_[0]),
        'intercept': list(classifier.intercept_)
    }

with open('model.json', 'w') as f:
    json.dump(exported_model, f)

print(f"\n‚úÖ Modelo exportado!")
```

Este script mostra:
- **Relat√≥rio detalhado** de precis√£o, recall, F1-score
- **Exemplos de erros** para entender o que o modelo confunde
- **Palavras mais importantes** que o modelo aprendeu

---

## üí° Dicas Finais

1. **Paci√™ncia**: Melhorar um modelo leva tempo e itera√ß√µes
2. **Qualidade > Quantidade**: 100 exemplos bem corrigidos > 500 mal corrigidos
3. **Consist√™ncia**: Mantenha o mesmo formato de corre√ß√£o sempre
4. **Teste regularmente**: Ap√≥s cada treinamento, teste em novos dados
5. **Documente**: Anote quais tipos de e-mail causam mais erros

**Boa sorte com o treinamento!** üéìüöÄ
